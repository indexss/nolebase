### **论文总结：《BiasDora: 探索视觉-语言模型中的隐藏偏见关联》**

---

## **1. 引言**

视觉-语言模型（VLMs）在多个领域展现出变革潜力，但研究表明它们可能会加强和扩散社会偏见。例如，VLMs可能会强化性别刻板印象，如女性被更多地与护理职业联系在一起，或将少数族裔与负面形象关联。然而，大多数研究仅关注于已有文献记录的偏见（如性别↔职业、种族↔犯罪等），这使得许多未被识别的隐性偏见无法得到检测和缓解。

本研究提出了一种系统性方法，通过**三种模态（文本到文本 T2T、文本到图像 T2I、图像到文本 I2T）**来探测VLMs中的偏见。研究目标包括：

1. 识别 9 种偏见维度上的隐性偏见关联；
2. 评估偏见的负面性、毒性和极端程度；
3. 发现现有研究未涉及的潜在偏见，并公开相关数据集（Dora）。

---

## **2. VLM 偏见探测方法**

研究采用 **三步管道方法** 来识别 VLMs 中的隐性偏见：

1. **VLM 解析**
    
    - **文本到文本 (T2T)**：通过单词补全任务，测试 VLM 生成的单词是否具有偏见。例如，给定提示 “This pierced person is a t_”，模型可能生成“thug”（恶棍）或“troublemaker”（麻烦制造者）。
    - **文本到图像 (T2I)**：使用不同提示词让模型生成图像，分析图像中的潜在偏见。例如，“生成一个穿孔的人”可能会倾向于特定的亚文化表现。
    - **图像到文本 (I2T)**：生成的图像再由 VLM 进行描述，以检测 VLM 在理解视觉信息时是否携带偏见。
2. **统计分析**
    
    - 计算统计显著性，使用 **TF-IDF** 衡量术语共现频率，并通过**p 值检验**过滤出有统计显著性的关联。
    - 应用 **Bonferroni 校正** 控制假阳性。
    - 采用 **情感分析和毒性检测** 评估偏见内容的负面性。
3. **偏见级别评估**
    
    - 通过 **GPT-4O** 进行 LLM 评估，对偏见程度进行 Likert 量表打分（1-5 级）。
    - 通过人工标注对模型评分进行验证，确保准确性。

---

## **3. 主要发现**

### **3.1 文本到文本 (T2T) 偏见**

- **GPT-4O 比 LLAMA 更容易产生负面偏见**，尤其是在性取向、身体外貌等维度上：
    - GPT-4O 生成的负面关联示例：
        - **同性恋者↔污秽（gay↔slur）**
        - **犹太人↔小偷（Jew↔thief）**
        - **意大利人↔绑架犯（Italian↔kidnapper）**
    - LLAMA 生成的负面关联示例：
        - **肥胖者↔自恋（obese people↔narcissistic）**
        - **黑人↔贫民窟（black person↔ghetto）**
        - **精神病人↔杀手（psychotic kid↔killer）**
- **性取向和身体外貌维度的负面关联比例最高**（见下图）。
- **职业刻板印象普遍存在**，如“医生↔男性”、“护士↔女性”。

### **3.2 文本到图像 (T2I) 偏见**

- **DALL-E 3 的性别和性取向偏见较低，但 STABLE DIFFUSION 更易反映负面偏见**：
    - STABLE DIFFUSION 在**性别相关的形象生成**方面的偏见比 DALL-E 3 更明显。
    - 例子：
        - **帮派成员↔涂鸦背景**
        - **肥胖者↔公园长椅**
        - **非洲人↔运动员**
- **国家/种族偏见显著**：
    - DALL-E 3 生成的图像强化了“**墨西哥人戴大草帽**”的刻板印象。
    - STABLE DIFFUSION 生成的“**英国人↔喝茶**”也显示了固定文化标签。

### **3.3 图像到文本 (I2T) 偏见**

- **LLAVA 在图像描述方面比 GPT-4O 产生更多负面偏见**：
    - **GPT-4O 在性别方面的偏见较低**，但在身体外貌和种族上仍然存在显著偏见。
    - **LLAVA 生成的负面关联示例**：
        - **盲人↔绝望（blind person↔despair）**
        - **酒鬼↔寡妇（alcoholic person↔widowed）**
        - **胖人↔不健康（fat person↔unhealthy）**
- **刻板印象仍然广泛存在**：
    - **白人↔压迫者（White people↔oppressors）**
    - **宗教信仰↔极端主义（Muslim↔Jihadist, Baptist↔Extremist）**

### **3.4 高度有害的偏见**

- **GPT-4O 和 LLAMA 生成的部分文本涉及极端有害的偏见**：
    - **种族仇恨**：
        - **非洲人↔大猩猩（African↔gorilla）**
        - **黑人↔斑马（Black person↔zebra）**
    - **人类-动物类比**：
        - **肥胖者↔鲸鱼（Fat person↔whale）**
        - **印度人↔斑马（Indian↔zebra）**
    - **政治/犯罪偏见**：
        - **伊拉克人↔恐怖分子（Iraqi↔terrorist）**
        - **穆斯林↔圣战（Muslim↔jihadist）**
        - **韩国人↔独裁者（Korean↔dictator）**

---

## **4. 研究贡献**

1. **提出了一种全面的探测方法**，能够自动发现**VLMs 未知的偏见**，而不是仅验证已知偏见。
2. **揭示了多种未被研究的刻板印象**，包括**年龄、职业、种族、性别、宗教、社会经济地位等维度的偏见**。
3. **提供了新的评估标准**，结合**统计显著性分析、毒性检测、情感分析和 LLM 评分**来衡量 VLM 偏见程度。
4. **公开 BiasDora 数据集**，为未来的偏见检测研究提供基准。

---

## **5. 研究局限性**

- **模型描述的客观性问题**：有些关联可能是中性描述（如“黑衣人”），但被误解为种族偏见。
- **筛选方法的改进**：目前使用 TF-IDF 进行筛选，未来可考虑使用**点互信息（PMI）**等方法优化结果。
- **量化偏见的局限性**：目前依赖毒性和情感分析作为偏见衡量标准，未来可以拓展更全面的指标。
- **LLM 评估自身偏见的挑战**：LLM 作为评估工具时，其自身偏见可能影响评分结果。

---

## **6. 结论**

BiasDora 提供了一种全面的方法来揭示 VLMs 中的隐性偏见，并发现了许多未被研究的刻板印象。这些偏见可能对社会产生深远影响，因此，理解并缓解它们至关重要。