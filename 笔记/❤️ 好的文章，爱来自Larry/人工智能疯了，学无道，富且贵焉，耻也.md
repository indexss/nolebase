---
tags:
  - AI
  - DL
  - ML
  - LLM
  - 不合时宜
---
# 人工智能疯了，学无道，富且贵焉，耻也

| Archive 自 | Archive 创建于      | 分类  | 原始作者        | 原始地址                                         | 原始资源创建时间         | 原始资源更新时间         |
| --------- | ---------------- | --- | ----------- | -------------------------------------------- | ---------------- | ---------------- |
| 知乎        | 2024-11-18 11:17 | 分类  | Qs.Zhang张拳石 | [链接](https://zhuanlan.zhihu.com/p/696644230) | 2024-05-08 13:59 | 2024-05-12 06:29 |


2023年当大部分人撤离了刷榜的阵地之后，人工智能越来越疯了，也要把我逼疯了，或许有一天我会以其他的形式留在学术界，而不是陪着大家演戏。我希望严肃的面对这个世界，无奈台面上很多论文放弃了起码的准则，论文背后的学者、舆论、科研攻略一齐编织着皇帝的新衣。

在多少交流场合，面向不同的学者的各式论文，我常常两句话打断你的报告，然后用5秒钟说出这一流派的根本问题，而你立马用10秒钟回复自己的无能为力，惊愕于我揭开整个方向的新衣，但是依然坚持你们中了很多论文而且，档次还是顶级。原谅我难以融入你们的默契。闭上嘴的南郭先生总是比抚起琴的阮籍看上去权威一些，但是耻也。

**就让我说说最近读到的顶级刊物的顶级论文。** 

论文1：关于深度学习中某个问题有个思考A，针对这个思考A提出了验证性实验（或验证性指标）B，基于前面的实验得到了新的insight C，然后提出算法D，解决了C的问题。但是A于B之间没有五服以内的直接的亲缘（数学）关系，A于C之间也没有讨论相同范畴的事物，D在算法上并没有直接对C中的问题进行证明建模的讨论，而以一种无心插柳柳成荫的形式解决了C。

论文2：做了个实验，构造了复杂任务A，然后在A的基础上做了些调整，构造了一个不太复杂的任务B，然后发现神经网络模型果然在相对简单的任务上性能更好一些（然后提出不同角度、不同指标论证这个结论），原因是B中给出了一些“捷径特征”——然后实验中果然发现了神经网络学到了这些捷径，这就是成果。

论文3：我们把这个模型在A、B、C、D、E等等不同任务上做了测试，发现此模型在A、B、C上新能比较好，而没有能力建模D、E等任务。记得16年，我审稿过程中，类似的实验发现被多个审稿人联合拒稿，理由是这些结论都是众所周知的，没有创新，但是这样的论文2024年却中了oral。

论文4：我发现了反直觉现象，把在A上训练一下，然后在B上微调一下，效果真好。然后A跟B看上去没有什么关系。

论文5：我发现了一个结论C。但是C究竟是什么，好像说不清楚，似是而非，没有数学描述，没有定义的边界。motivation的哲学，实验设计凭直觉，得出的结论。。。

论文6：是一篇理论，看上去挺唬人了。然后经验上大概30%的论文都可以证明出明显的错误。还有些论文十多年都没有真正影响过应用。

**AI圈子里面一些客观事实，总是被忽略和回避** 

1. 虽然总体上模型性能还在随着惯性在进步，但是人工智能发展的根本维度十多年来在一直减少，但是学术界从业人数在指数性上升。发展维度上，从开始的设计图模型功性能结构，到深度学习的调参调结构，再到大模型时代的什么都调不动，留给学者探索的空间一直在下降，但是学术工作者的人数在不断增加，这意味着什么？就像2019年周围人都劝我买房，说肯定不会跌的，但是客观规律在那里，大家也知道这些为什么从上到下没有人愿意去提。
2. 不往远说，5年前，如果一篇论文所希望解决的目标和所提算法之间没有明确的关系，是会被喷的，大概率无法中稿。
3. 5年前，一篇实验发现性的论文，如果所发现的结论是长期以来的常识，缺少new insights，是无法中稿的。
4. 7年前，如果一篇工程性技术需要在大量不同的数据集、任务上充分证明出算法优秀性能不是某个特定数据集上的巧合，否则算法的扎实程度会受质疑，然后拒稿。

上面随便说一些大众可以听懂的、偏工程的内容，但是2-4这些要求在2024已经被频繁突破掉，已经很少在当前审稿语境下提及。我相信，这些是每个从业10年以上的学者都看得到的问题。

**为什么不给自己立一些原则呢？** 

1. 当看到在炼丹框架下的方法论很难得到根本性的突破，为什么不阻止自己做这些类型呢？
2. 说说XAI方向：工程性post-hoc explanation of DNNs无法给出严谨的解释，无法在重大应用中给出绝对的、可靠的评估，已经是七八年以来的共识了，为什么在大量position papers发表以后，大量工程性解释算法还是持续地发表呢？为什么不静下来想一想踏踏实实的核心问题呢？
3. 暂且不提创新性，有些论文的结论是correct，有些论文的结论是wrong，但是很大一部分论文not even wrong（可能一些人不清楚这是什么意思）。
4. 当无法对一个现象或结论的边界范围做出数学上的描述时，能不能先不急于把这个结论公布到学术界。可以只有实验而没有证明，但是对论题本身是不是要有个清晰的界定。

对上述原则的坚持，在审稿过程中甚至常常成为拒稿的原因。

**何去何从** 

我记得最早在2023年10月的时候，就跟一些同学和同事聊到过我的一个预测，后面也是不是提及。当一个领域的最顶级刊物中30%-50%以上的论文无法清晰地表达出其所得结论的范畴时，或者无法以任何形式（甚至没有资格）作为另一篇论文的研究基础时，这个领域的口碑就会急转直下，因为大家会发现很大一部分研究不会直接为领域的发展做出贡献，哪怕形式上的贡献。这里，甚至可以不考虑因为性能不济而不被引用的问题，而是很多论文中似是而非的结论根本无法被清晰地提炼表达出来，给出一个明确的指引。

我认为这个时间点在2026年以前。

**大家都说很多工程性实验论文可以给出一些启发式的insights，为未来的扎实理论突破做铺垫。这是一个美好的幻想。** 除了一些及其浮夸的无法严格验证其普适性的现象孤例以外，绝大部分insights与2016年的认知并没有本质的拓展。

大家在忙着各种事儿，忙着在规则体系内寻找向上的路径，但是对这个规则没有质疑和反思。这样的现象遍布全球，科举文化下尤甚。

看到一个扩张的时代，就如当年的大炼钢铁，大家都清楚领域中在做什么，但是没有人高声说哪怕一句话，不断地新建、扩张、捷报频传，等着2026的到来。世上何曾存在过什么荣耀，不滑稽自欺已是千难万难。

![](assets/4c40ccf31eb144ed739cdded6cffded9_MD5.webp)

[Qs.Zhang张拳石：这两年，我究竟做了些什么（2021-2023）](https://zhuanlan.zhihu.com/p/661781861)

[Qs.Zhang张拳石：神经网络可解释性研究中常被忽略的几个根本问题](https://zhuanlan.zhihu.com/p/694930219)

[Qs.Zhang张拳石：AI从技术到科学：神经网络中的概念符号涌现的发现与证明](https://zhuanlan.zhihu.com/p/618870800)

[Qs.Zhang张拳石：证明神经网络精细决策逻辑可以严格解释为符号化等效交互概念](https://zhuanlan.zhihu.com/p/693747946)

[Qs.Zhang张拳石：敢问深度学习路在何方，从统一12种提升对抗迁移性的算法说起](https://zhuanlan.zhihu.com/p/546433296)

[Qs.Zhang张拳石：神经网络可解释性：正本清源，论统一14种输入重要性归因算法](https://zhuanlan.zhihu.com/p/610774894)

[Qs.Zhang张拳石：可解释性理论系列：反思深度学习，去伪存真、合众归一198 赞同 · 16 评论文章211 赞同 · 17 评论文章220 赞同 · 17 评论文章](https://zhuanlan.zhihu.com/p/524075490)

[上交大张拳石：深度学习可解释性，从百家争鸣到合众归一​mp.weixin.qq.com/s/KXdSwv_ypx1l2AIHrVb-3A​mp.weixin.qq.com/s/KXdSwv_ypx1l2AIHrVb-3A​mp.weixin.qq.com/s/KXdSwv_ypx1l2AIHrVb-3A​mp.weixin.qq.com/s/KXdSwv_ypx1l2AIHrVb-3A](https://mp.weixin.qq.com/s/KXdSwv_ypx1l2AIHrVb-3A)

[Qs.Zhang张拳石：ICLR 2022 Oral论文中得分排名前五的高分论文“发现并证明神经网络表征瓶颈”（得分10,8,8,8）923 赞同 · 25 评论文章995 赞同 · 25 评论文章1030 赞同 · 25 评论文章1067 赞同 · 26 评论文章](https://zhuanlan.zhihu.com/p/468569001)

[Qs.Zhang张拳石：神经网络的博弈交互解释性（一）：前言，漂在零丁洋里的体系268 赞同 · 20 评论文章275 赞同 · 20 评论文章](https://zhuanlan.zhihu.com/p/264871522/)

1. [前言，漂在零丁洋里的体系](https://zhuanlan.zhihu.com/p/264871522/)
2. [博弈交互概念、定义、定理、推论、与计算](https://zhuanlan.zhihu.com/p/264953129)
3. 动机：建模知识，连接性能
4. 背景基础Shapley value
5. 双变元博弈交互
6. 多变元博弈交互，及其近似计算
7. 多阶博弈交互
8. 相关定理与推论
9. 自然语言交互树
10. [博弈交互与知识表达的关](https://zhuanlan.zhihu.com/p/386548661/)
11. 探索中低阶博弈交互所建模的视觉概念及泛化能力
12. 探索高阶博弈交互所建模的视觉概念
13. 神经网络对纹理概念的建模相比形状概念更具有弹性
14. [博弈交互与对抗攻击的关系，推导证明与实验](https://zhuanlan.zhihu.com/p/264873308/)
15. 证明博弈交互与对抗迁移性的负相关关系
16. 证明多个前人迁移性增强算法可近似归纳解释为对博弈交互的抑制
17. 交互[损失函数](https://www.zhihu.com/search?q=%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2928247749%7D)与迁移性的增强
18. [博弈交互与泛化能力的关系，推导证明与实验](https://zhuanlan.zhihu.com/p/345561960)
19. 探索交互强度与泛化能力的关系
20. 证明Dropout对交互强度的抑制
21. 交互强度损失函数与泛化能力的提升
22. [从博弈交互层面解释对抗鲁棒性](https://zhuanlan.zhihu.com/p/361686461)
23. 对抗攻击在多阶博弈交互上的效用
24. 从知识构成的层面探索对抗训练提升鲁棒性的原因
25. 去芜存菁：解释并萃取多个前人防御算法中公共的有效机理
26. [神经网络对抗迁移性：从神农尝百草到精炼与萃取](https://zhuanlan.zhihu.com/p/369883667)
27. [完善Shapley value理论体系，建模并学习基准值](https://zhuanlan.zhihu.com/p/395674023/)
28. [在博弈交互体系内，对“美”提出一个假设性建模](https://zhuanlan.zhihu.com/p/395709713)
29. [可解释性核心——神经网络的知识表达瓶颈](https://zhuanlan.zhihu.com/p/422420088/)
30. 博弈交互与神经网络知识表征
31. 发现并理论解释神经网络的表达瓶颈
32. 突破表达瓶颈及探究不同交互复杂度下的表达能力
33. [敢问深度学习路在何方，从统一12种提升对抗迁移性的算法说起](https://zhuanlan.zhihu.com/p/546433296/)
34. [神经网络可解释性：正本清源，论统一14种输入重要性归因算法](https://zhuanlan.zhihu.com/p/610774894/)
35. [对智能模型中概念涌现的证明](https://zhuanlan.zhihu.com/p/633531725)
36. [数学证明神经网络中符号化概念涌现的现象](https://zhuanlan.zhihu.com/p/626642885)
37. [可解释的哈萨尼网络](https://zhuanlan.zhihu.com/p/643213054)
38. 通过博弈交互 某某某某某某
39. 通过博弈交互 某某某某某某