# Language Modeling
è¿™ä¸€éƒ¨åˆ†çš„è¯¦ç»†å†…å®¹åœ¨æˆ‘çš„CS224Nç³»åˆ—ç¬”è®°ä¸­æœ‰æ›´å¥½çš„è¯´æ˜ï¼Œè¿™é‡Œåªæ˜¯æ¢—æ¦‚æ€§åœ°è®²äº†ä¸€ä¸‹ã€‚
[4 - Language Models and RNN](../ğŸ’¬%20CS224N-Natural%20Language%20Processing%20with%20Deep%20Learning/4%20-%20Language%20Models%20and%20RNN.md)
LMçš„è¿›åŒ–pathï¼š
![](assets/Pasted%20image%2020250425194234.webp)
![](assets/Pasted%20image%2020250425194248.webp)
![](assets/Pasted%20image%2020250425194302.webp)
![](assets/Pasted%20image%2020250425194343.webp)
## è¯­è¨€æ¨¡å‹
å¯ä»¥é¢„æµ‹å³å°†å‡ºç°çš„å•è¯çš„æ¨¡å‹
è¯­è¨€æ¨¡å‹çš„ä¸€èˆ¬ä»»åŠ¡ï¼š
- ç»™æ•´å¥ç®—æ¦‚ç‡ï¼Œä¹Ÿå°±æ˜¯â€œè¿™æ•´ä¸²è¯å‡ºç°çš„æ¦‚ç‡æœ‰å¤šå¤§â€ï¼Œå¯ç”¨äºè¯„ä»·å¥å­â€œåˆç†â€ä¸å¦ã€æˆ–åœ¨æœºå™¨ç¿»è¯‘é‡ŒåšæŸæœç´¢ï¼ˆbeam searchï¼‰æ‰“åˆ†ã€‚ï¼š
  $$P(W)=P(w_1,w_2,\ldots,w_n)$$
- é¢„æµ‹ä¸‹ä¸€ä¸ªè¯ï¼Œ
  $$P(w_t\mid w_1,w_2,\ldots,w_{t-1})$$
  è¿™æ­£æ˜¯â€œç»™å‰æ–‡ï¼ŒçŒœä¸‹ä¸€ä¸ªè¯ä¼šæ˜¯ä»€ä¹ˆâ€çš„ä»»åŠ¡ï¼Œæ˜¯è‡ªå›å½’è¯­è¨€æ¨¡å‹å¸¸è§çš„è®­ç»ƒï¼æ¨ç†å½¢å¼ã€‚

è¿™ä¸¤ä¸ªç›®æ ‡å…¶å®ç­‰ä»·ï¼Œå› ä¸ºè‹¥ä½ èƒ½å‡†ç¡®ç®—å‡ºæ¯ä¸ªæ¡ä»¶æ¦‚ç‡ï¼Œå°±èƒ½ä¹˜èµ·æ¥å¾—åˆ°æ•´å¥æ¦‚ç‡ï¼š
$$P(w_1,\ldots,w_n)=\prod_{t=1}^nP(w_t\mid w_1,\ldots,w_{t-1}).$$
åä¹‹ï¼Œåªè¦å»ºäº†ä¸€ä¸ªèƒ½é¢„æµ‹ä¸‹ä¸€ä¸ªè¯çš„æ¨¡å‹ï¼Œå°±èƒ½é€šè¿‡ç´¯ä¹˜å¾—åˆ°æ•´å¥çš„æ¦‚ç‡ã€‚
ç„¶è€Œï¼Œç”¨ç®€å•çš„æ•°æ•°ç›¸é™¤ï¼Œä¹Ÿå°±æ˜¯é¢‘ç‡ä¼°è®¡æ¦‚ç‡åœ¨LMä¸­æ˜¯è¡Œä¸é€šçš„ï¼š
$$P(\mathrm{â€œblueâ€}\mid\text{â€œThe water of Walden Pond is so beautifully"})=\frac{C\left(\mathrm{â€œThe~}\ldots\text{ beautifully blue"}\right)}{C\left(\mathrm{â€œThe~}\ldots\text{ beautifully"}\right)}$$
è¿™æ˜¯å› ä¸ºï¼Œå¯èƒ½çš„å¥å­æ•°é‡çˆ†ç‚¸ï¼Œä½ æ²¡æ³•ç»Ÿè®¡ã€‚
æ ¹æ®é“¾å¼æ³•åˆ™ï¼Œæˆ‘ä»¬å¯ä»¥çŸ¥é“ï¼š
$$P(\mathrm{â€œblueâ€}\mid\underbrace{\text{The water of Walden Pond is so beautifully}}_{\text{æ•´ä¸ªå‰æ–‡}})\mathrm{~=~}P(w_n\mid w_1,\ldots,w_{n-1})\mathrm{~,}$$
ä½†æ˜¯è¿™è¿˜æ˜¯æœ‰ç‚¹é•¿ã€‚ç„¶è€Œï¼Œæ ¹æ®ä¿„å›½æ•°å­¦å®¶ **Andrei Markov** æå‡ºâ€”â€”æˆ‘ä»¬å¯ä»¥å‡è®¾â€œå½“å‰çŠ¶æ€åªä¾èµ–æœ‰é™ä¸ªå†å²çŠ¶æ€â€ã€‚åœ¨è¯­è¨€æ¨¡å‹é‡Œï¼Œæœ€å¸¸è§çš„å°±æ˜¯**ä¸€é˜¶é©¬å°”å¯å¤«**ï¼ˆbigramï¼‰ï¼š
$$\boxed{P(w_n\mid w_1,\ldots,w_{n-1})\mathrm{~}\approx\mathrm{~}P(w_n\mid w_{n-1})}$$
ä¹Ÿå°±æ˜¯è¯´ï¼Œâ€œblueâ€å‡ºç°çš„æ¦‚ç‡ï¼Œåªçœ‹å®ƒå‰é¢ç´§é‚»çš„ä¸€ä¸ªè¯â€œbeautifullyâ€ï¼Œè€Œå¿½ç•¥æ›´è¿œçš„ä¸Šä¸‹æ–‡ã€‚è€Œå¦‚æœæ˜¯ké˜¶é©¬å°”å¯å¤«ï¼Œé‚£ä¹ˆå°±æ˜¯
$$P(w_n\mid w_{1:n-1})\mathrm{~}\approx\mathrm{~}P(w_n\mid w_{n-k:n-1}).$$
è¿™æ­£å¥½å¯ä»¥æ¨å¹¿åˆ°n-gramã€‚
æœ‰äº†ä¸€é˜¶é©¬å°”å¯å¤«ï¼ˆbi-gramï¼‰ï¼Œæˆ‘ä»¬å°±å¯ä»¥æ ¹æ®é¢‘ç‡ä¼°è®¡æ¦‚ç‡äº†ï¼š
![](assets/Pasted%20image%2020250425200318.webp)
æ¨å¹¿åˆ°n-gramä¹Ÿå¯ä»¥ï¼Œä½†æ˜¯æœ‰é—®é¢˜ï¼šN-grams æ— æ³•å¤„ç†é•¿è·ç¦»ä¾èµ–å…³ç³»ã€‚è§£å†³æ–¹æ³•å°±æ˜¯ï¼šNeural Language Models

### è¯„ä¼°LM
#### Extrinsic (in-vivo) Evaluation
åœ¨ä»»åŠ¡ä¸­çœ‹æ•ˆæœ
#### Intrinsic (in-vitro) evaluation
Expensive, time-consumingï¼Œä¸æ³›åŒ–åˆ°å…¶ä»–ä»»åŠ¡
perplexity

### Perplexity
è¿™ä¸ªmetricæˆ‘åœ¨CS224Nä¸­æè¿‡ï¼š[4 - Language Models and RNN](../ğŸ’¬%20CS224N-Natural%20Language%20Processing%20with%20Deep%20Learning/4%20-%20Language%20Models%20and%20RNN.md)
å›°æƒ‘åº¦å¯ä»¥ç†è§£ä¸ºâ€œå¹³å‡æ¯ä¸€æ­¥æ¨¡å‹è¦åœ¨å¤šå°‘ç§å¯èƒ½çš„ä¸‹ä¸€ä¸ªè¯ä¸­åšé€‰æ‹©â€ï¼›è¶Šåå¥½æ­£ç¡®çš„ä¸‹ä¸€ä¸ªè¯ï¼Œå›°æƒ‘åº¦å°±è¶Šä½ã€‚
![](assets/Pasted%20image%2020250425200629.webp)
![](assets/Pasted%20image%2020250425200804.webp)
![](assets/Pasted%20image%2020250425200928.webp)
## Auto-Regressive Language Models
### Greedy Search
![](assets/Pasted%20image%2020250425201039.webp)
### Beam Search
![](assets/Pasted%20image%2020250425201052.webp)
Beam Searchå¾€è¿œçœ‹ä¸€æ­¥ï¼Œä¹Ÿå°±æ˜¯ç›´æ¥çœ‹ä¸¤æ­¥ã€‚
- â€œniceâ€ â†’ â€œwomanâ€ (0.5Ã—0.4=0.20), â†’ â€œhouseâ€ (0.5Ã—0.3=0.15), â€¦    
- â€œdogâ€ â†’ â€œhasâ€ (0.4Ã—0.9=0.36), â†’ â€œrunsâ€ (0.4Ã—0.05=0.02), â€¦
### Sampling
![](assets/Pasted%20image%2020250425201318.webp)
**é‡‡æ ·**ï¼šä¸æ˜¯æ€»é€‰æ¦‚ç‡æœ€å¤§çš„è¯ï¼Œè€Œæ˜¯ä»è¿™ä¸ªåˆ†å¸ƒé‡ŒéšæœºæŠ½æ ·ã€‚
å½“ç„¶ä¹Ÿå¯ä»¥æ¸©åº¦è°ƒèŠ‚ï¼Œåœ¨ softmax å‰é™¤ä»¥ä¸€ä¸ªæ¸©åº¦å‚æ•° Tï¼š
$$P_T(w)\propto\exp(\frac{\ell_w}{T}),$$
- **T<1ï¼šå¢å¼ºé«˜æ¦‚ç‡è¯ï¼ˆæ›´â€œè´ªå¿ƒâ€ï¼‰ï¼›
- **T>1**ï¼šè®©åˆ†å¸ƒæ›´å¹³ç¼“ï¼Œå¢åŠ å¤šæ ·æ€§ã€‚
å½“æ¸©åº¦é™ä½æ—¶ï¼Œâ€œniceâ€ çš„é‡‡æ ·æ¦‚ç‡ä» 0.5 æå‡åˆ° 0.75ï¼Œå…¶ä»–è¯ç›¸åº”ä¸‹é™ã€‚

### Top-K Sampling
![](assets/Pasted%20image%2020250425201527.webp)
Top-K é‡‡æ ·ï¼ˆå›ºå®šè¯è¡¨å¤§å°ï¼‰,åœ¨æ¯ä¸€æ­¥ï¼Œåªä¿ç•™æ¦‚ç‡ **æœ€é«˜çš„ K ä¸ª** è¯ï¼ŒæŠŠå…¶ä»–æ‰€æœ‰è¯çš„æ¦‚ç‡éƒ½ç½®ä¸º 0ï¼Œå†å¯¹è¿™ K ä¸ªè¯é‡æ–°åšå½’ä¸€åŒ–ç„¶åéšæœºæŠ½æ ·ã€‚
å›ºå®šä¿ç•™å‰ K ä¸ªè¯
### Top-P Sampling
![](assets/Pasted%20image%2020250425201618.webp)
åœ¨æ¯ä¸€æ­¥ï¼Œä¸å†å›ºå®šä¿ç•™ K ä¸ªè¯ï¼Œè€Œæ˜¯æ‰¾åˆ°æœ€å°çš„è¯é›† Vtop-pä½¿å¾—å®ƒä»¬çš„ç´¯ç§¯æ¦‚ç‡ â‰¥ pï¼ˆä¾‹å¦‚ 0.9ï¼‰ã€‚ç„¶ååªåœ¨è¿™ä¸ªåŠ¨æ€å¤§å°çš„é›†åˆé‡Œåšéšæœºé‡‡æ ·ã€‚
ä¿ç•™æœ€å°‘çš„è¯ï¼Œç›´åˆ°ç´¯ç§¯æ¦‚ç‡ â‰¥ p

## Word Embedding
**N-gram æ¨¡å‹**â€”â€”æ¯”å¦‚ bigramã€trigramâ€”â€”æœ¬è´¨ä¸Šæ˜¯åœ¨è®­ç»ƒè¯­æ–™é‡Œ â€œæ•°æ•°å†é™¤â€ï¼ŒæŠŠæ¯ä¸ªå‰ç¼€åé¢è·Ÿç€æ¯ä¸ªè¯çš„é¢‘ç‡éƒ½è®°ä¸‹æ¥ã€‚
å®ƒ**å®Œå…¨**ä¾èµ–è®­ç»ƒè¯­æ–™ä¸­çš„å‡ºç°æƒ…å†µâ€”â€”åªæœ‰åœ¨è®­ç»ƒé›†ä¸­è§è¿‡çš„ä¸Šä¸‹æ–‡-è¯å¯¹æ‰æœ‰éé›¶æ¦‚ç‡ï¼›å¦‚æœæµ‹è¯•æ—¶é‡åˆ°å’Œè®­ç»ƒæ—¶åˆ†å¸ƒä¸å®Œå…¨ä¸€æ ·çš„è¯­è¨€ï¼Œæ¨¡å‹å°±ä¼šâ€œæ¯«æ— å‡†å¤‡â€åœ°å´©æºƒâ€”â€”å› ä¸ºå®ƒæ²¡è§è¿‡ã€å°±ç»™ **0** æ¦‚ç‡ï¼

è¿™ç§æƒ…å†µperplexityéƒ½ç®—ä¸å‡ºæ¥ã€‚
- ç»å…¸çš„ N-gram å¹³æ»‘ï¼ˆåŠ ä¸€ã€Katz å›é€€ã€Kneserâ€“Neyâ€¦â€¦ï¼‰éƒ½æ˜¯ä¸ºäº†è§£å†³â€œé›¶æ¦‚ç‡â€é—®é¢˜ï¼Œè®©æœªè§è¿‡çš„ç»„åˆä¹Ÿèƒ½åˆ†åˆ°ä¸€ç‚¹â€œé»˜è®¤â€è´¨é‡ã€‚
- ä½†è¿™äº›æ–¹æ³•å¾€å¾€éœ€è¦æ‰‹å·¥è°ƒå‚ï¼Œä¸”åœ¨é«˜ç»´ï¼ˆå¤§ä¸Šä¸‹æ–‡é•¿åº¦ã€å¤§è¯è¡¨ï¼‰æ—¶æ•ˆæœä¹Ÿæœ‰é™ã€‚

æ‰€ä»¥ï¼Œæˆ‘ä»¬è¦å¼•å…¥è¯å‘é‡ï¼Embedding æ¥æ•‘åœºã€‚ç”¨è¿ç»­çš„ã€ä½ç»´çš„å®æ•°å‘é‡æ¥è¡¨ç¤ºæ¯ä¸ªè¯ï¼Œä½¿å¾—è¯­ä¹‰æˆ–ç”¨æ³•ç›¸ä¼¼çš„è¯åœ¨å‘é‡ç©ºé—´é‡Œâ€œæŒ¨å¾—è¿‘â€

å¸¸ç”¨çš„å¯ä»¥ä¸‹è½½åˆ°çš„é™æ€æ¨¡å‹ï¼šWord2vecï¼ŒGloVeã€‚

![](assets/Pasted%20image%2020250425202025.webp)
## Neural Architectures for Language Modeling
è¿™éƒ¨åˆ†åœ¨ [8 - Pretraining](../ğŸ’¬%20CS224N-Natural%20Language%20Processing%20with%20Deep%20Learning/8%20-%20Pretraining.md) ä¸­è¯¦ç»†è®¨è®ºè¿‡ã€‚
è·¯çº¿ï¼š
- Feed Forward Network
- Recurrent NN
- LSTM RNN
- Stacked LSTM NN
- Stacked Bidirectional LSTMs
- Transformer
	- Decoders
		- GPT, Claude,Llama
	- Encoders
		- BERT family
	- Encoder-decoders
		- Flan-T5, Whisper
### BERT - Encoder only
![](assets/Pasted%20image%2020250425202413.webp)
BERTèƒ½ç”Ÿæˆå—ï¼Ÿå¯å¡«ç©ºï¼Œå´ä¸æ“…é•¿â€œç»­å†™â€ã€‚å¯ä»¥å˜é€šï¼Œè®©BERTç”Ÿæˆï¼Œæ”¹æˆå¡«ç©ºæ¨¡å¼å³å¯ã€‚
ä¸‹é¢ä¾‹å­æ˜¯ç”¨ BERT åšå¥å­åµŒå…¥ï¼Œå†æ¥ä¸€ä¸ªç®€å•æƒ…ç»ªåˆ†ç±»å™¨ï¼š
é¦–å…ˆç”¨DistilBERT æŠŠæ¯ä¸ªå¥å­æ˜ å°„æˆä¸€ä¸ª **768 ç»´** çš„å‘é‡è¡¨ç¤ºï¼š
![](assets/Pasted%20image%2020250425202710.webp)
ç„¶ååˆ’åˆ†è®­ç»ƒé›† / æµ‹è¯•é›†ï¼š
![](assets/Pasted%20image%2020250425202748.webp)
ç”¨ä¸€ä¸ªè½»é‡çº§çš„ scikit-learn `LogisticRegression`
è®­ç»ƒé›†çš„åµŒå…¥å‘é‡ + å¯¹åº”æ ‡ç­¾ã€‚
æœ€ä¼˜åŒ–ä¸€ä¸ªäºŒåˆ†ç±»çš„å¯¹æ•°æŸå¤±ï¼Œè®©æ¨¡å‹å­¦ä¼šä» 768 ç»´ç‰¹å¾é¢„æµ‹æ­£è´Ÿé¢ã€‚
![](assets/Pasted%20image%2020250425202800.webp)
### GPT2 - Decoder only
![](assets/Pasted%20image%2020250425202909.webp)
![](assets/Pasted%20image%2020250425202916.webp)
![](assets/Pasted%20image%2020250425202928.webp)
![](assets/Pasted%20image%2020250425202938.webp)
![](assets/Pasted%20image%2020250425202951.webp)
#### å¾®è°ƒLMæ¥ä½¿å…¶é€‚ç”¨äºä½ çš„ä»»åŠ¡
![](assets/Pasted%20image%2020250425203041.webp)
#### ä½¿ç”¨RL from Human Feedback (RLHF)
![](assets/Pasted%20image%2020250425203123.webp)
LLMè¿˜å¯ä»¥åš
â€¢ Zero-Shot Learning â€¢ One-Shot Learning â€¢ In-Context Learning