https://www.cjig.cn/rc-pub/front/front-article/download/61664179/lowqualitypdf/%E9%9D%A2%E5%90%91%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB%E7%9A%84%E5%85%AC%E5%B9%B3%E6%80%A7%E7%A0%94%E7%A9%B6%E8%BF%9B%E5%B1%95.pdf

```
("computer vision" OR "CV" OR "image recognition" OR "object detection" OR "semantic segmentation" OR "diffusion" OR "gan") AND ("bias" OR "fairness" OR "algorithmic discrimination" OR "dataset bias" OR "model bias")
```

采纳

---

## 0. 引言（Introduction）

1. **图像识别发展历程：**
    
    - 传统方法依赖手工特征，近年在大规模数据与深度学习的驱动下飞速发展
    - 在医疗诊断、行政执法等高风险场景中应用逐渐增多
2. **公平性引起关注：**
    
    - 图像识别系统表现出偏见或歧视，引发伦理与安全问题
    - 例如：相机对亚洲人眨眼误判、黑肤色人群识别错误率较高等
    - 公平性已成为人工智能的重要议题，与准确率一起影响系统的可信与可用
3. **论文目标：**
    
    - 对图像识别公平性的研究进展进行全面梳理
    - 覆盖偏见的来源、常用数据集和评价指标、去偏见算法分类
    - 展望未来发展方向和挑战

---

## 1. 图像识别公平性概述

### 1.1 公平性和去偏见的定义

- **偏见属性（敏感属性）：** 颜色、背景、纹理、性别、种族、年龄等
- **目标属性：** 模型真正需要识别或分类的属性（如数字、人脸身份等）
- 公平性：在不同偏见属性的群体上达到**一致的性能**
- 去偏见与公平性：当前主要关注“结果公平”，尽量消除因偏见属性带来的不公平

### 1.2 偏见来源

1. **数据不平衡：**
    - 训练集常见到某些群体样本过多，另一些过少
    - 模型偏向最小化整体误差，忽略少数群体
2. **属性间的虚假关联：**
    - 模型易捕捉到“目标—偏见”错误关联（如数字识别依赖颜色而非形状）
    - 导致对冲突样本（不符合该关联的样本）识别较差
3. **群体差异性：**
    - 不同群体（如肤色深浅、年龄高低）对模型有不同要求
    - 当模型无法兼顾各群体需求时，就会导致偏见

### 1.3 细分任务上的公平性

- **图像分类：** 常见属性间可能一一对应（数字与颜色），易形成明显偏见
- **人脸识别/行人重识别：** 目标属性（身份）与偏见属性（种族/性别）本身耦合度较高，解耦更困难
- **差异：** 数据结构、偏见机理和去偏见策略都可能因任务类型而有所区别

---

## 2. 图像识别公平性数据集

1. **彩色MNIST系列：**
    - Colored MNIST / Multi-Color MNIST / Biased MNIST
    - 将原始数字添加颜色或更多干扰信息，观察模型是否依赖颜色等非目标属性
2. **Corrupted CIFAR-10：**
    - 通过人为损坏（模糊、噪声等）建立类别与损坏类型的关联
3. **9-Class ImageNet：**
    - 从ImageNet筛选9个超类，关注背景纹理等偏见
4. **BAR动作识别：**
    - 6类动作和典型背景高度相关，如攀岩-岩壁，测试集中去除该对应
5. **bFFHQ / CelebA / UTKFace / IMDB / FairFace等人脸属性数据集：**
    - 主要用于研究性别、种族、年龄等人口学偏见
6. **RFW / BUPT-Balancedface / BUPT-Globalface：**
    - 人脸识别（身份）领域，控制或模拟种族分布，衡量在不同种族群体上的性能差异

---

## 3. 图像识别公平性评价指标

1. **识别率：**
    - 无偏测试集上的识别准确率/偏见冲突样本上的准确率
2. **几率均等（Equalized Odds, EOD）：**
    - TPR和FPR在不同偏见属性群体间需相等
3. **机会均等（Equal Opportunity, EOP）：**
    - 真阳率（TPR）在不同群体间相等
4. **识别率方差：**
    - 不同群体间识别率的方差度量公平性

---

## 4. 图像识别公平性算法

### 4.1 重加权（重采样）

- **核心思路：** 提升少数群体样本权重或采样频率、降低多数群体样本权重
- **优点：** 操作简单，可结合损失值、梯度等信息自适应地发现并放大偏见冲突样本
- **局限：** 无法从根本上解决问题；可能牺牲一定准确率，数据利用率也较低

### 4.2 图像增强

- **GAN等生成网络**：将多数群体样本转换为少数群体的属性，或合成新图像
- **优点：** 从数据层面平衡分布，理论上可兼顾准确率与公平性
- **局限：** GAN训练不稳定，容易模型坍塌，生成质量控制较难

### 4.3 特征增强

- **操作特征层**：对偏见特征进行扰动或编辑，再让模型保持判定一致
- **代表方法**：对具有相同目标类别但不同偏见的样本进行MixUp、风格迁移等
- **优点：** 训练更稳定，不必显式生成新图像；
- **局限：** 增强后特征可能缺乏直观语义解释，多样性有限

### 4.4 特征解耦

- **本质：** 在特征空间中“分离”目标信息与偏见信息，或最小化两者间的互信息
- **常用技术：** 对抗学习、互信息最小化、正交分解等
- **利弊：** 能从根本上消除虚假关联，但容易陷入准确率-公平性的权衡；对于人脸等任务（偏见属性即面部信息）更困难

### 4.5 度量学习

- **思路：** 让同目标（不同偏见）的样本在特征空间中聚集，不同目标（同偏见）样本分离
- **实现：** 对比学习；正对: “目标相同但偏见不同”；负对: “目标不同但偏见相同”
- **优点：** 直接、易理解，在特征空间进行强约束
- **局限：** 依赖偏见标签，未知偏见场景效果受限

### 4.6 模型自适应

- **原因：** 单一模型难以兼顾群体差异，将网络结构或超参数进行自适应调整
- **实例：** 在人脸识别中对不同种族调整卷积核或大间距损失的间距参数
- **优点：** 针对性强，可在保障准确率的同时显著提升公平性
- **局限：** 目前主要在细分任务（如人脸识别）尝试，通用性仍待验证

### 4.7 后处理

- **不改训练流程，仅在推理阶段或输出分数上进行校准**
- **适用场景：** 已有或黑盒模型，快速修正其偏见
- **缺陷：** 某些训练数据或模型结构固有的偏见难以事后完全消除

### 4.8 主流数据集上的测试结果

- **核心发现：**
    1. 重加权、图像增强、特征解耦等均可有效减小偏见；
    2. 不同任务和数据集上，最优方法可能不同
    3. 人脸识别中，模型自适应往往提升更显著

---

## 5. 机遇与挑战

1. **数据集和评价指标有待进一步完善**
    - 偏见多种多样，亟需更多元的公平性数据集与更统一的评估方案
2. **未知偏见的处理问题**
    - 现实中无法总是掌握偏见标签，多偏见/隐性偏见如何发现和去除需深入研究
3. **准确率与公平性的权衡仍待突破**
    - 二者往往冲突，需要方法在牺牲最少性能的同时最大化公平性
4. **细分任务新趋势**
    - 图像分类中因果干预；人脸识别从群体公平逐渐拓展到“个体公平”
5. **从图像到视频**
    - 视频识别的偏见开始受到关注，如动作识别中场景偏见、人脸识别中的年龄/性别偏见等

---

## 6. 结语（Conclusion）

1. **图像识别公平性的重要性：**
    - 社会价值与实用性兼具，是可信人工智能不可或缺的环节
2. **研究现状：**
    - 数据集、评价指标与去偏见算法均已初具规模，但仍处在发展初期
    - 多种类型的去偏见思路（重加权、图像/特征增强、解耦、度量学习、模型自适应、后处理等）均有探索
3. **未来展望：**
    - 继续丰富数据集、评价指标；
    - 更深入地研究未知偏见、多偏见场景；
    - 兼顾准确率与公平性；
    - 拓展到视频等领域并强化因果推理等新技术